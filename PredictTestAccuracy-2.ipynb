{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlraUIVB2eksFYDw2LS9Z9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"p_67SyyGDlfw"},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.datasets import make_classification\n","from sklearn.metrics import log_loss\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from tqdm.notebook import tqdm  # progress bars\n","from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n","from scipy.stats import linregress\n","\n","# For reproducibility\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","#########################################\n","# Custom split function\n","#########################################\n","def custom_split(X, y, train_ratio, train_min, test_min, random_state=None):\n","    n = X.shape[0]\n","    classes = np.unique(y)\n","    n_classes = len(classes)\n","    if n < train_min + test_min:\n","        raise ValueError(f\"Not enough samples: n={n}, train_min={train_min}, test_min={test_min}\")\n","    if random_state is not None:\n","        np.random.seed(random_state)\n","    T = int(round(train_ratio * n))\n","    if T < train_min:\n","        T = train_min\n","    if n - T < test_min:\n","        T = n - test_min\n","    # If T is less than number of classes, force training set to have one sample per class.\n","    if T < n_classes:\n","        train_idx = []\n","        for cls in classes:\n","            indices_cls = np.where(y == cls)[0]\n","            chosen = np.random.choice(indices_cls, size=1, replace=False)\n","            train_idx.append(chosen[0])\n","        train_idx = np.array(train_idx)\n","        test_idx = np.setdiff1d(np.arange(n), train_idx)\n","        if len(test_idx) < test_min:\n","            raise ValueError(\"Test set too small after forcing one sample per class.\")\n","        return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n","    else:\n","        if n_classes >= 2:\n","            sss = StratifiedShuffleSplit(n_splits=1, train_size=T, test_size=n-T, random_state=random_state)\n","            train_idx, test_idx = next(sss.split(X, y))\n","            return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n","        else:\n","            indices = np.random.permutation(n)\n","            train_idx = indices[:T]\n","            test_idx = indices[T:]\n","            return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n","\n","#########################################\n","# Cross Validation Accuracy Functions\n","#########################################\n","def get_cv_folds(y, k=5):\n","    counts = np.bincount(y.astype(int))\n","    n_possible = np.min(counts)\n","    return min(k, n_possible) if n_possible >= 2 else 1\n","\n","def compute_cv_accuracy_nn(X_train, y_train, num_epochs, input_dim):\n","    k = get_cv_folds(y_train, k=5)\n","    if k < 2:\n","        model = create_nn_model(input_dim)\n","        model.fit(X_train, y_train, epochs=num_epochs, batch_size=32, verbose=0)\n","        _, acc = model.evaluate(X_train, y_train, verbose=0)\n","        return acc\n","    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n","    accuracies = []\n","    for train_index, val_index in skf.split(X_train, y_train):\n","        X_cv_train, X_cv_val = X_train[train_index], X_train[val_index]\n","        y_cv_train, y_cv_val = y_train[train_index], y_train[val_index]\n","        model_cv = create_nn_model(input_dim)\n","        model_cv.fit(X_cv_train, y_cv_train, epochs=num_epochs, batch_size=32, verbose=0)\n","        _, acc = model_cv.evaluate(X_cv_val, y_cv_val, verbose=0)\n","        accuracies.append(acc)\n","    return np.mean(accuracies)\n","\n","def compute_cv_accuracy_rf(X_train, y_train):\n","    k = get_cv_folds(y_train, k=5)\n","    if k < 2:\n","        model_cv = RandomForestClassifier(n_estimators=100, random_state=42)\n","        model_cv.fit(X_train, y_train)\n","        return model_cv.score(X_train, y_train)\n","    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n","    accuracies = []\n","    for train_index, val_index in skf.split(X_train, y_train):\n","        X_cv_train, X_cv_val = X_train[train_index], X_train[val_index]\n","        y_cv_train, y_cv_val = y_train[train_index], y_train[val_index]\n","        model_cv = RandomForestClassifier(n_estimators=100, random_state=42)\n","        model_cv.fit(X_cv_train, y_cv_train)\n","        acc = model_cv.score(X_cv_val, y_cv_val)\n","        accuracies.append(acc)\n","    return np.mean(accuracies)\n","\n","def compute_cv_accuracy_sv(X_train, y_train):\n","    k = get_cv_folds(y_train, k=5)\n","    if k < 2:\n","        model_cv = SVC(probability=True, random_state=42)\n","        model_cv.fit(X_train, y_train)\n","        return model_cv.score(X_train, y_train)\n","    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n","    accuracies = []\n","    for train_index, val_index in skf.split(X_train, y_train):\n","        X_cv_train, X_cv_val = X_train[train_index], X_train[val_index]\n","        y_cv_train, y_cv_val = y_train[train_index], y_train[val_index]\n","        model_cv = SVC(probability=True, random_state=42)\n","        model_cv.fit(X_cv_train, y_cv_train)\n","        acc = model_cv.score(X_cv_val, y_cv_val)\n","        accuracies.append(acc)\n","    return np.mean(accuracies)\n","\n","#########################################\n","# Settings\n","#########################################\n","dataset_sizes = [100, 250, 500, 1000]  # minimum dataset size = 100\n","split_ratios = [0.05, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n","num_epochs = 50\n","experiments = []\n","model_types = [\"NN\", \"RF\", \"SV\"]\n","\n","#########################################\n","# NN Model Creation Function\n","#########################################\n","def create_nn_model(input_dim):\n","    model = keras.Sequential([\n","        keras.Input(shape=(input_dim,)),\n","        keras.layers.Dense(32, activation='relu'),\n","        keras.layers.Dense(16, activation='relu'),\n","        keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","#########################################\n","# Experiment Loop\n","#########################################\n","for X_size in tqdm(dataset_sizes, desc=\"Dataset sizes\"):\n","    X, y = make_classification(n_samples=X_size, n_features=20,\n","                               n_informative=15, n_redundant=5, random_state=42)\n","    for ratio in tqdm(split_ratios, desc=\"Split ratios\", leave=False):\n","        try:\n","            # Full dataset split: require training set min = 5 and test set min = 1.\n","            X_train_full, X_test, y_train_full, y_test = custom_split(\n","                X, y, train_ratio=ratio, train_min=5, test_min=1, random_state=int(ratio * 100))\n","        except ValueError as e:\n","            tqdm.write(f\"Skipping ratio {ratio} for dataset size {X_size}: {e}\")\n","            continue\n","        for m_type in tqdm(model_types, desc=\"Model types\", leave=False):\n","            if m_type == \"NN\":\n","                cv_acc = compute_cv_accuracy_nn(X_train_full, y_train_full, num_epochs, X.shape[1])\n","                model = create_nn_model(X.shape[1])\n","                history = model.fit(X_train_full, y_train_full, epochs=num_epochs, batch_size=32, verbose=0)\n","                _, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","                final_train_acc = history.history['accuracy'][-1]\n","                avg_train_acc = np.mean(history.history['accuracy'])\n","            elif m_type == \"RF\":\n","                cv_acc = compute_cv_accuracy_rf(X_train_full, y_train_full)\n","                model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                model.fit(X_train_full, y_train_full)\n","                test_accuracy = model.score(X_test, y_test)\n","                final_train_acc = model.score(X_train_full, y_train_full)\n","                avg_train_acc = final_train_acc  # RF is constant.\n","            elif m_type == \"SV\":\n","                cv_acc = compute_cv_accuracy_sv(X_train_full, y_train_full)\n","                model = SVC(probability=True, random_state=42)\n","                model.fit(X_train_full, y_train_full)\n","                test_accuracy = model.score(X_test, y_test)\n","                final_train_acc = model.score(X_train_full, y_train_full)\n","                avg_train_acc = final_train_acc  # SV is constant.\n","\n","            exp_label = f\"DS {X_size}, Split {int(ratio*100)}/{100-int(ratio*100)}, {m_type}\"\n","            experiments.append({\n","                'dataset_size': X_size,\n","                'ratio': ratio,\n","                'model_type': m_type,\n","                'cv_acc': cv_acc,\n","                'final_train_acc': final_train_acc,\n","                'avg_train_acc': avg_train_acc,\n","                'test_acc': test_accuracy,\n","                'label': exp_label\n","            })\n","\n","#########################################\n","# Plotting: Five Figures\n","#########################################\n","colors = {'NN': 'blue', 'RF': 'green', 'SV': 'orange'}\n","\n","# Figure A: Test Accuracy vs Average Training Accuracy\n","plt.figure(figsize=(8,6))\n","for m in model_types:\n","    filtered = [exp for exp in experiments if exp['model_type'] == m]\n","    x = np.array([exp['avg_train_acc'] for exp in filtered])\n","    y = np.array([exp['test_acc'] for exp in filtered])\n","    plt.scatter(x, y, color=colors[m], alpha=0.7, label=f\"{m} Data\")\n","    if len(np.unique(x)) > 1:\n","        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n","        R2 = r_value**2\n","        x_vals = np.linspace(min(x), max(x), 100)\n","        y_vals = slope * x_vals + intercept\n","        plt.plot(x_vals, y_vals, color=colors[m], linestyle='-', label=f\"{m} Fit\")\n","        plt.annotate(f\"{m}: p = {p_value:.3g}, R² = {R2:.3g}\",\n","                     xy=(0.05, 0.9 - 0.1*model_types.index(m)), xycoords='axes fraction',\n","                     bbox=dict(boxstyle=\"round\", fc=\"w\"))\n","plt.xlabel(\"Average Training Accuracy\")\n","plt.ylabel(\"Test Accuracy\")\n","plt.title(\"Test Accuracy vs Average Training Accuracy\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Figure B: Test Accuracy vs Training Proportion\n","plt.figure(figsize=(8,6))\n","for m in model_types:\n","    filtered = [exp for exp in experiments if exp['model_type'] == m]\n","    x = np.array([exp['ratio'] for exp in filtered])\n","    y = np.array([exp['test_acc'] for exp in filtered])\n","    plt.scatter(x, y, color=colors[m], alpha=0.7, label=f\"{m} Data\")\n","    if len(np.unique(x)) > 1:\n","        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n","        R2 = r_value**2\n","        x_vals = np.linspace(min(x), max(x), 100)\n","        y_vals = slope * x_vals + intercept\n","        plt.plot(x_vals, y_vals, color=colors[m], linestyle='-', label=f\"{m} Fit\")\n","        plt.annotate(f\"{m}: p = {p_value:.3g}, R² = {R2:.3g}\",\n","                     xy=(0.05, 0.9 - 0.1*model_types.index(m)), xycoords='axes fraction',\n","                     bbox=dict(boxstyle=\"round\", fc=\"w\"))\n","plt.xlabel(\"Training Proportion\")\n","plt.ylabel(\"Test Accuracy\")\n","plt.title(\"Test Accuracy vs Training Proportion\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Figure C: Test Accuracy vs Mean CV Accuracy\n","plt.figure(figsize=(8,6))\n","for m in model_types:\n","    filtered = [exp for exp in experiments if exp['model_type'] == m]\n","    x = np.array([exp['cv_acc'] for exp in filtered])\n","    y = np.array([exp['test_acc'] for exp in filtered])\n","    plt.scatter(x, y, color=colors[m], alpha=0.7, label=f\"{m} Data\")\n","    if len(np.unique(x)) > 1:\n","        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n","        R2 = r_value**2\n","        x_vals = np.linspace(min(x), max(x), 100)\n","        y_vals = slope * x_vals + intercept\n","        plt.plot(x_vals, y_vals, color=colors[m], linestyle='-', label=f\"{m} Fit\")\n","        plt.annotate(f\"{m}: p = {p_value:.3g}, R² = {R2:.3g}\",\n","                     xy=(0.05, 0.9 - 0.1*model_types.index(m)), xycoords='axes fraction',\n","                     bbox=dict(boxstyle=\"round\", fc=\"w\"))\n","plt.xlabel(\"Mean CV Accuracy\")\n","plt.ylabel(\"Test Accuracy\")\n","plt.title(\"Test Accuracy vs Mean CV Accuracy\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Figure D: Test Accuracy vs Dataset Size\n","plt.figure(figsize=(8,6))\n","for m in model_types:\n","    filtered = [exp for exp in experiments if exp['model_type'] == m]\n","    x = np.array([exp['dataset_size'] for exp in filtered])\n","    y = np.array([exp['test_acc'] for exp in filtered])\n","    plt.scatter(x, y, color=colors[m], alpha=0.7, label=f\"{m} Data\")\n","    if len(np.unique(x)) > 1:\n","        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n","        R2 = r_value**2\n","        x_vals = np.linspace(min(x), max(x), 100)\n","        y_vals = slope * x_vals + intercept\n","        plt.plot(x_vals, y_vals, color=colors[m], linestyle='-', label=f\"{m} Fit\")\n","        plt.annotate(f\"{m}: p = {p_value:.3g}, R² = {R2:.3g}\",\n","                     xy=(0.05, 0.9 - 0.1*model_types.index(m)), xycoords='axes fraction',\n","                     bbox=dict(boxstyle=\"round\", fc=\"w\"))\n","plt.xlabel(\"Dataset Size\")\n","plt.ylabel(\"Test Accuracy\")\n","plt.title(\"Test Accuracy vs Dataset Size\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Figure E: Test Accuracy vs Final Training Accuracy\n","plt.figure(figsize=(8,6))\n","for m in model_types:\n","    filtered = [exp for exp in experiments if exp['model_type'] == m]\n","    x = np.array([exp['final_train_acc'] for exp in filtered])\n","    y = np.array([exp['test_acc'] for exp in filtered])\n","    plt.scatter(x, y, color=colors[m], alpha=0.7, label=f\"{m} Data\")\n","    if len(np.unique(x)) > 1:\n","        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n","        R2 = r_value**2\n","        x_vals = np.linspace(min(x), max(x), 100)\n","        y_vals = slope * x_vals + intercept\n","        plt.plot(x_vals, y_vals, color=colors[m], linestyle='-', label=f\"{m} Fit\")\n","        plt.annotate(f\"{m}: p = {p_value:.3g}, R² = {R2:.3g}\",\n","                     xy=(0.05, 0.9 - 0.1*model_types.index(m)), xycoords='axes fraction',\n","                     bbox=dict(boxstyle=\"round\", fc=\"w\"))\n","plt.xlabel(\"Final Training Accuracy\")\n","plt.ylabel(\"Test Accuracy\")\n","plt.title(\"Test Accuracy vs Final Training Accuracy\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Summary Tables\n","print(\"\\nSummary of Final Metrics (Unsorted):\")\n","print(\"Dataset Size | Train/Test Ratio | Model | Mean CV Accuracy | Avg Train Accuracy | Final Train Accuracy | Test Accuracy\")\n","for exp in experiments:\n","    ratio_percent = f\"{int(exp['ratio']*100)}/{100-int(exp['ratio']*100)}\"\n","    print(f\"{exp['dataset_size']:12d} | {ratio_percent:15s} | {exp['model_type']:5s} | {exp['cv_acc']:.3f}   | {exp['avg_train_acc']:.3f}   | {exp['final_train_acc']:.3f}   | {exp['test_acc']:.3f}\")\n","\n","sorted_experiments = sorted(experiments, key=lambda exp: exp['test_acc'], reverse=True)\n","print(\"\\nRanked by Test Accuracy (Highest to Lowest):\")\n","print(\"Rank | Dataset Size | Train/Test Ratio | Model | Mean CV Accuracy | Avg Train Accuracy | Final Train Accuracy | Test Accuracy\")\n","for idx, exp in enumerate(sorted_experiments, start=1):\n","    ratio_percent = f\"{int(exp['ratio']*100)}/{100-int(exp['ratio']*100)}\"\n","    print(f\"{idx:4d} | {exp['dataset_size']:12d} | {ratio_percent:15s} | {exp['model_type']:5s} | {exp['cv_acc']:.3f}   | {exp['avg_train_acc']:.3f}   | {exp['final_train_acc']:.3f}   | {exp['test_acc']:.3f}\")\n"]}]}